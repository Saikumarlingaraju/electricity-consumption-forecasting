{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b5ea0f",
   "metadata": {},
   "source": [
    "# Electricity Consumption Forecasting Project\n",
    "\n",
    "## Overview\n",
    "This notebook forecasts household electricity consumption using time-series aware machine learning models.\n",
    "\n",
    "**Dataset**: `household_power_consumption.csv`  \n",
    "**Target**: `Global_active_power` (kilowatts)  \n",
    "**Models**: Random Forest, XGBoost, Linear Regression, Decision Tree\n",
    "\n",
    "## Key Improvements in This Version\n",
    "- Fixed datetime parsing (removed invalid `format='mixed'`)\n",
    "- Consolidated data cleaning into single section\n",
    "- Implemented chronological train/test split for time-series\n",
    "- Fixed shape mismatch bugs in predictions\n",
    "- Added data diagnostics and drift detection\n",
    "- Improved feature engineering with lag features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abf56e1",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea812ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn import tree\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1deb5c5",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282066e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('household_power_consumption.csv', low_memory=False)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d993dca4",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing (Consolidated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e9aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Replace '?' with NaN\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Step 2: Convert numeric columns\n",
    "cols_to_convert = ['Global_active_power', 'Global_reactive_power', 'Voltage',\n",
    "                   'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(f\"Missing values before cleaning:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# Step 3: Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Shape after cleaning: {df.shape}\")\n",
    "print(f\"Missing values after cleaning: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c64a4",
   "metadata": {},
   "source": [
    "## 4. DateTime Processing (FIXED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime index (FIXED: removed invalid format='mixed')\n",
    "df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# Drop any rows where datetime parsing failed\n",
    "df = df.dropna(subset=['Datetime'])\n",
    "\n",
    "# Set as index and sort\n",
    "df.set_index('Datetime', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Drop original date/time columns and any 'index' column\n",
    "df.drop(columns=['Date', 'Time', 'index'], errors='ignore', inplace=True)\n",
    "\n",
    "print(f\"‚úÖ DateTime index created\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"Total duration: {(df.index.max() - df.index.min()).days} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cdfd8e",
   "metadata": {},
   "source": [
    "## 5. Data Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset recency\n",
    "last_reading = df.index.max()\n",
    "days_since_last = (pd.Timestamp.today() - last_reading).days\n",
    "\n",
    "print(\"üìä Dataset Diagnostics\")\n",
    "print(f\"First reading: {df.index.min()}\")\n",
    "print(f\"Last reading:  {last_reading}\")\n",
    "print(f\"Days since last reading: {days_since_last}\")\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "\n",
    "if days_since_last > 365:\n",
    "    print(f\"‚ö†Ô∏è WARNING: Dataset is {days_since_last} days old. Consider using recent data for production forecasting.\")\n",
    "elif days_since_last > 180:\n",
    "    print(f\"‚ö†Ô∏è CAUTION: Dataset is {days_since_last} days old. Validate model performance on recent data.\")\n",
    "else:\n",
    "    print(\"‚úÖ Dataset is relatively recent.\")\n",
    "\n",
    "# Display last 10 records\n",
    "print(\"\\nLast 10 records:\")\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd08217",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad28d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based features\n",
    "df['hour'] = df.index.hour\n",
    "df['day'] = df.index.day\n",
    "df['month'] = df.index.month\n",
    "df['day_of_week'] = df.index.dayofweek\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "# Lag features (previous hour consumption)\n",
    "df['lag_1h'] = df['Global_active_power'].shift(60)  # assuming minute-level data\n",
    "df['lag_24h'] = df['Global_active_power'].shift(60*24)  # 24 hours ago\n",
    "\n",
    "# Rolling statistics (3-hour window)\n",
    "df['rolling_mean_3h'] = df['Global_active_power'].rolling(window=180, min_periods=1).mean()\n",
    "df['rolling_std_3h'] = df['Global_active_power'].rolling(window=180, min_periods=1).std()\n",
    "\n",
    "# Drop rows with NaN from lag features\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(f\"‚úÖ Features engineered. Final shape: {df.shape}\")\n",
    "print(f\"\\nFeature list:\\n{df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f141e1d",
   "metadata": {},
   "source": [
    "## 7. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ece1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"üìä Summary Statistics\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a151e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].hist(df['Global_active_power'], bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Distribution of Global Active Power')\n",
    "axes[0].set_xlabel('Global Active Power (kW)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "sns.boxplot(data=df, y='Global_active_power', color='lightcoral', ax=axes[1])\n",
    "axes[1].set_title('Box Plot - Global Active Power')\n",
    "axes[1].set_ylabel('Kilowatts')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4efda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly consumption pattern\n",
    "plt.figure(figsize=(12, 6))\n",
    "hourly_avg = df.groupby('hour')['Global_active_power'].mean()\n",
    "plt.plot(hourly_avg.index, hourly_avg.values, marker='o', linewidth=2, markersize=8)\n",
    "plt.title('Average Electricity Consumption by Hour of Day', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Average Power (kW)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(24))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a73481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily consumption trend (sample)\n",
    "plt.figure(figsize=(14, 5))\n",
    "df['Global_active_power'].resample('D').mean().plot(linewidth=1.5)\n",
    "plt.title('Daily Average Electricity Consumption Over Time', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Power (kW)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b92261",
   "metadata": {},
   "source": [
    "## 8. Train/Test Split (CHRONOLOGICAL - FIXED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60983f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "feature_cols = ['Global_reactive_power', 'Voltage', 'Global_intensity',\n",
    "                'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3',\n",
    "                'hour', 'day', 'month', 'day_of_week', 'is_weekend',\n",
    "                'lag_1h', 'lag_24h', 'rolling_mean_3h', 'rolling_std_3h']\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['Global_active_power']\n",
    "\n",
    "# CHRONOLOGICAL SPLIT (80/20) - respects time order\n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print(\"‚úÖ Chronological Train/Test Split Complete\")\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples ({X_train.index.min()} to {X_train.index.max()})\")\n",
    "print(f\"Test set:     {X_test.shape[0]:,} samples ({X_test.index.min()} to {X_test.index.max()})\")\n",
    "print(f\"Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a1a92",
   "metadata": {},
   "source": [
    "## 9. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305e30e",
   "metadata": {},
   "source": [
    "### 9.1 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f08b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "rmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"\\nüìä Random Forest Performance\")\n",
    "print(f\"MAE:  {mae_rf:.4f} kW\")\n",
    "print(f\"RMSE: {rmse_rf:.4f} kW\")\n",
    "print(f\"R¬≤:   {r2_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27bafa7",
   "metadata": {},
   "source": [
    "### 9.2 XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1faac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=7, random_state=42, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"\\nüìä XGBoost Performance\")\n",
    "print(f\"MAE:  {mae_xgb:.4f} kW\")\n",
    "print(f\"RMSE: {rmse_xgb:.4f} kW\")\n",
    "print(f\"R¬≤:   {r2_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b3ce5",
   "metadata": {},
   "source": [
    "### 9.3 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2966b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree\n",
    "print(\"Training Decision Tree...\")\n",
    "dt_model = DecisionTreeRegressor(max_depth=15, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions (FIXED: predict on X_test, not single sample)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "rmse_dt = mean_squared_error(y_test, y_pred_dt, squared=False)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "print(f\"\\nüìä Decision Tree Performance\")\n",
    "print(f\"MAE:  {mae_dt:.4f} kW\")\n",
    "print(f\"RMSE: {rmse_dt:.4f} kW\")\n",
    "print(f\"R¬≤:   {r2_dt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f4633",
   "metadata": {},
   "source": [
    "### 9.4 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57dc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression\n",
    "print(\"Training Linear Regression...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "rmse_lr = mean_squared_error(y_test, y_pred_lr, squared=False)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"\\nüìä Linear Regression Performance\")\n",
    "print(f\"MAE:  {mae_lr:.4f} kW\")\n",
    "print(f\"RMSE: {rmse_lr:.4f} kW\")\n",
    "print(f\"R¬≤:   {r2_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c80cc40",
   "metadata": {},
   "source": [
    "## 10. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost', 'Decision Tree', 'Linear Regression'],\n",
    "    'MAE': [mae_rf, mae_xgb, mae_dt, mae_lr],\n",
    "    'RMSE': [rmse_rf, rmse_xgb, rmse_dt, rmse_lr],\n",
    "    'R¬≤': [r2_rf, r2_xgb, r2_dt, r2_lr]\n",
    "})\n",
    "\n",
    "results = results.sort_values('RMSE')\n",
    "\n",
    "print(\"\\nüèÜ Model Performance Comparison (sorted by RMSE)\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "best_model_name = results.iloc[0]['Model']\n",
    "print(f\"\\n‚úÖ Best Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52bfdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# MAE comparison\n",
    "axes[0].barh(results['Model'], results['MAE'], color='skyblue')\n",
    "axes[0].set_xlabel('Mean Absolute Error (kW)')\n",
    "axes[0].set_title('MAE Comparison')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE comparison\n",
    "axes[1].barh(results['Model'], results['RMSE'], color='lightcoral')\n",
    "axes[1].set_xlabel('Root Mean Squared Error (kW)')\n",
    "axes[1].set_title('RMSE Comparison')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eada0fb7",
   "metadata": {},
   "source": [
    "## 11. Prediction Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d1def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted (first 500 test samples)\n",
    "n_samples = 500\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(range(n_samples), y_test.values[:n_samples], label='Actual', color='black', linewidth=2, alpha=0.7)\n",
    "plt.plot(range(n_samples), y_pred_rf[:n_samples], label='Random Forest', linestyle='--', linewidth=1.5, alpha=0.8)\n",
    "plt.plot(range(n_samples), y_pred_xgb[:n_samples], label='XGBoost', linestyle='--', linewidth=1.5, alpha=0.8)\n",
    "plt.plot(range(n_samples), y_pred_dt[:n_samples], label='Decision Tree', linestyle=':', linewidth=1.5, alpha=0.7)\n",
    "plt.plot(range(n_samples), y_pred_lr[:n_samples], label='Linear Regression', linestyle='-.', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "plt.title('Actual vs Predicted Electricity Consumption (First 500 Test Samples)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Global Active Power (kW)')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction error distribution (Random Forest)\n",
    "errors_rf = y_test - y_pred_rf\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(errors_rf, bins=50, color='purple', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "axes[0].set_title('Prediction Error Distribution (Random Forest)', fontweight='bold')\n",
    "axes[0].set_xlabel('Error (kW)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot\n",
    "axes[1].scatter(y_test, y_pred_rf, alpha=0.3, s=10)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Actual (kW)')\n",
    "axes[1].set_ylabel('Predicted (kW)')\n",
    "axes[1].set_title('Actual vs Predicted Scatter (Random Forest)', fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Error statistics (Random Forest):\")\n",
    "print(f\"Mean error: {errors_rf.mean():.4f} kW\")\n",
    "print(f\"Std error:  {errors_rf.std():.4f} kW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ab7604",
   "metadata": {},
   "source": [
    "## 12. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2cf2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (Random Forest)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance, y='feature', x='importance', palette='viridis')\n",
    "plt.title('Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feature_importance.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc13be8",
   "metadata": {},
   "source": [
    "## 13. Time-Series Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70553251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series cross-validation with Random Forest\n",
    "print(\"Running Time Series Cross-Validation...\\n\")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):\n",
    "    X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    model_cv = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",
    "    model_cv.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    y_pred_cv = model_cv.predict(X_val_cv)\n",
    "    rmse_cv = mean_squared_error(y_val_cv, y_pred_cv, squared=False)\n",
    "    cv_scores.append(rmse_cv)\n",
    "    \n",
    "    print(f\"Fold {fold}: RMSE = {rmse_cv:.4f} kW\")\n",
    "\n",
    "print(f\"\\nAverage RMSE across folds: {np.mean(cv_scores):.4f} ¬± {np.std(cv_scores):.4f} kW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd0d081",
   "metadata": {},
   "source": [
    "## 14. Residual Analysis Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals over time (check for drift)\n",
    "test_df = pd.DataFrame({\n",
    "    'actual': y_test,\n",
    "    'predicted': y_pred_rf,\n",
    "    'error': y_test - y_pred_rf\n",
    "}, index=y_test.index)\n",
    "\n",
    "# Monthly average error\n",
    "monthly_error = test_df['error'].resample('M').mean()\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(monthly_error.index, monthly_error.values, marker='o', linewidth=2, markersize=8)\n",
    "plt.axhline(0, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Zero Error')\n",
    "plt.title('Monthly Average Prediction Error Over Time (Drift Detection)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Error (kW)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for systematic drift\n",
    "if abs(monthly_error.iloc[-1]) > abs(monthly_error.iloc[0]) * 1.5:\n",
    "    print(\"‚ö†Ô∏è WARNING: Potential model drift detected. Consider retraining.\")\n",
    "else:\n",
    "    print(\"‚úÖ No significant drift detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e5cf32",
   "metadata": {},
   "source": [
    "## 15. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e3931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model (assuming Random Forest or XGBoost is best)\n",
    "if mae_rf < mae_xgb:\n",
    "    best_model = rf_model\n",
    "    model_name = 'random_forest'\n",
    "else:\n",
    "    best_model = xgb_model\n",
    "    model_name = 'xgboost'\n",
    "\n",
    "model_filename = f'best_model_{model_name}.joblib'\n",
    "joblib.dump(best_model, model_filename)\n",
    "\n",
    "print(f\"‚úÖ Best model saved as '{model_filename}'\")\n",
    "print(f\"\\nTo load the model later:\")\n",
    "print(f\"model = joblib.load('{model_filename}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cefe892",
   "metadata": {},
   "source": [
    "## 16. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b168e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úÖ Dataset processed: {len(df):,} records\")\n",
    "print(f\"‚úÖ Date range: {df.index.min().date()} to {df.index.max().date()}\")\n",
    "print(f\"‚úÖ Features engineered: {len(feature_cols)}\")\n",
    "print(f\"‚úÖ Models trained: 4 (Random Forest, XGBoost, Decision Tree, Linear Regression)\")\n",
    "print(f\"‚úÖ Best model: {best_model_name}\")\n",
    "print(f\"‚úÖ Best RMSE: {results.iloc[0]['RMSE']:.4f} kW\")\n",
    "print(f\"\\nüìä RECOMMENDATIONS:\")\n",
    "print(\"  1. Monitor model performance monthly for drift\")\n",
    "print(\"  2. Retrain with new data every 3-6 months\")\n",
    "print(\"  3. Consider adding weather/temperature features\")\n",
    "print(\"  4. Implement automated retraining pipeline\")\n",
    "print(\"  5. Add holiday calendar features for better accuracy\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
